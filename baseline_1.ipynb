{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer\n",
    "\n",
    "from pymystem3 import Mystem \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "from catboost.text_processing import Tokenizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv',index_col=0,encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 3.16 s, total: 18 s\n",
      "Wall time: 45.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mst = Mystem()\n",
    "def lemmatize(text):\n",
    "    text = ''.join( re.sub(r\"([^a-z\\'])+\",' ',text.lower()) )\n",
    "#     print(text)\n",
    "#     text = re.sub('( )+',' ',text)\n",
    "    return ''.join( mst.lemmatize(text)).strip('\\n')                \n",
    "\n",
    "# lemmatize(df.text[2])                    \n",
    "df['lemmas'] = df.text.apply(lemmatize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.4 ms, sys: 769 µs, total: 43.2 ms\n",
      "Wall time: 41.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tr,te = train_test_split(df, test_size = .25, shuffle = True)\n",
    "X = [ 'lemmas' ] \n",
    "y = 'toxic'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_options =  {\n",
    "    \"tokenizers\" : [{\n",
    "        \"tokenizer_id\" : \"Space\",\n",
    "        \"delimiter\" : \" ,\",\n",
    "        \"lowercasing\" : \"true\",\n",
    "#        \"lemmatizing\" : \"true\",\n",
    "        \"split_by_set\": \"true\"                    \n",
    "    },{\n",
    "    'tokenizer_id': 'Sense',\n",
    "    'separator_type': 'BySense'\n",
    "    }],\n",
    "\n",
    "    \"dictionaries\" : [{\"dictionary_id\" : \"BiGram\",\n",
    "            \"max_dictionary_size\" : \"100000\",\n",
    "            \"occurrence_lower_bound\" : \"10\",\n",
    "            \"gram_order\" : \"2\"\n",
    "        },{\n",
    "        \"dictionary_id\" : \"Word\",\n",
    "        \"occurrence_lower_bound\" : \"20\",\n",
    "        \"gram_order\" : \"1\"\n",
    "    }],\n",
    "\n",
    "    \"feature_processing\" : {\n",
    "        \"default\" : [{\n",
    "            \"dictionaries_names\" : [\"Word\",\"BiGram\"],\n",
    "            \"feature_calcers\" : [\"BoW\"],\n",
    "            \"tokenizers_names\" : [\"Sense\"]\n",
    "        }]\n",
    "        \n",
    "    }\n",
    "}\n",
    "cbm = CatBoostClassifier(learning_rate = .1,n_estimators =2048 ,\n",
    "                         bootstrap_type='Bernoulli',subsample=.2,\n",
    "                         text_processing = text_options,\n",
    "                         verbose= 128, eval_metric='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3708287\ttotal: 204ms\tremaining: 6m 58s\n",
      "128:\tlearn: 0.6737659\ttotal: 12.3s\tremaining: 3m 2s\n",
      "256:\tlearn: 0.7175710\ttotal: 25.7s\tremaining: 2m 58s\n",
      "384:\tlearn: 0.7363346\ttotal: 38.3s\tremaining: 2m 45s\n",
      "512:\tlearn: 0.7488202\ttotal: 50.5s\tremaining: 2m 31s\n",
      "640:\tlearn: 0.7581945\ttotal: 1m 3s\tremaining: 2m 18s\n",
      "768:\tlearn: 0.7670983\ttotal: 1m 16s\tremaining: 2m 6s\n",
      "896:\tlearn: 0.7746432\ttotal: 1m 29s\tremaining: 1m 54s\n",
      "1024:\tlearn: 0.7811028\ttotal: 1m 42s\tremaining: 1m 42s\n",
      "1152:\tlearn: 0.7874686\ttotal: 1m 56s\tremaining: 1m 30s\n",
      "1280:\tlearn: 0.7940774\ttotal: 2m 9s\tremaining: 1m 17s\n",
      "1408:\tlearn: 0.7998683\ttotal: 2m 25s\tremaining: 1m 5s\n",
      "1536:\tlearn: 0.8053408\ttotal: 2m 41s\tremaining: 53.6s\n",
      "1664:\tlearn: 0.8104453\ttotal: 2m 55s\tremaining: 40.4s\n",
      "1792:\tlearn: 0.8144944\ttotal: 3m 9s\tremaining: 26.9s\n",
      "1920:\tlearn: 0.8196858\ttotal: 3m 22s\tremaining: 13.4s\n",
      "2047:\tlearn: 0.8235783\ttotal: 3m 36s\tremaining: 0us\n",
      "f1_score:0.7416\t\n",
      "accuracy_score:0.9562\t\n",
      "precision_score:0.8811\t\n",
      "recall_score:0.6402\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35574,   338],\n",
       "       [ 1407,  2504]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "p_tr = Pool(tr[X],tr[y], text_features = X ) \n",
    "p_te = Pool( te[X], text_features = X )\n",
    "cbm.fit(p_tr)    \n",
    "pr = cbm.predict(p_te)\n",
    "for metric in [f1_score,accuracy_score,precision_score,recall_score]:\n",
    "    print( f\"{metric.__name__}:{round( metric(te[y],pr), 4)}\\t\" )\n",
    "confusion_matrix(te[y],pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cbm.fit(tr[X],tr[y],verbose=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = cbm.predict(p_te)\n",
    "confusion_matrix(te[y],pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(.2,.6,.025):\n",
    "    cbm.set_probability_threshold(t)\n",
    "    pr = cbm.predict(te[X])\n",
    "    #confusion_matrix(te[y],pr)\n",
    "    \n",
    "    s = f\"{round(t,2)} -->\\t\"\n",
    "    for metric in [f1_score,accuracy_score,precision_score,recall_score]:\n",
    "        s+=f\"{metric.__name__}:{round( metric(te[y],pr), 4)}\\t\"\n",
    "    print(s)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm.set_probability_threshold(.36)\n",
    "pr = cbm.predict(te[X])\n",
    "for metric in [f1_score,accuracy_score,precision_score,recall_score]:\n",
    "    print( f\"{metric.__name__}:{round( metric(te[y],pr), 4)}\\t\" )\n",
    "\"confusion_matrix:\",confusion_matrix(te[y],pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# params_grid ={\n",
    "#     'learning_rate':[0.3,.1,.03,.01],\n",
    "#     'auto_class_weights':['Balanced']\n",
    "# }\n",
    "# cbc = GridSearchCV( \n",
    "#     CatBoostClassifier( eval_metric='F1',text_features = X,tokenizers=verbose= 100  ),\n",
    "#     params_grid,\n",
    "#     scoring='f1_weighted',\n",
    "#     cv= 4)  \n",
    "# cbc.fit(tr[X],tr[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = cbc.predict(te[X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  CatBoostClassifier( eval_metric='F1',eval_period=50,text_features = X,verbose= 100,n_estimators=500 , learning_rate=.03 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
